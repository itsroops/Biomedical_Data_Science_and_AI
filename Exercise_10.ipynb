{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Guha Neogi_Elsayed_Islam_Sheet10",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVLHeU0W4coU"
      },
      "source": [
        "# Exercise Sheet 10\n",
        "## Loading and pre-processing of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JyBJc5MGewqC"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_breast_cancer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLlHPvJgexjH"
      },
      "source": [
        "cancer = load_breast_cancer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecGYIZ9yezk-"
      },
      "source": [
        "# some preprocessing\n",
        "X = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
        "Y = pd.DataFrame(cancer.target, columns = [\"class\"])\n",
        "Y = Y.replace({0: \"malignant\", 1 : \"benign\"})\n",
        "class_names = ['malignant','benign']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-h8cbGG85CR"
      },
      "source": [
        "A nice explaination about decision trees and random forests can be found here: https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QADR4fmKA8S"
      },
      "source": [
        "# Question 1 - Decision Trees"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W6SRWlc9I5M"
      },
      "source": [
        "### Q1 - 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EgaaVMc4nws"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bmm6umyywuSv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "c43d080f-af6a-493f-be5e-33417a627a8a"
      },
      "source": [
        "# hint: https://scikit-learn.org/stable/modules/tree.html\n",
        "\n",
        "#Creating the classifier object wiht a max depth of 2\n",
        "clf = DecisionTreeClassifier(max_depth=2, random_state=20)\n",
        "\n",
        "# Fitting the model\n",
        "clf.fit(X,Y)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=2, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=20, splitter='best')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qb3ApyBkK1Bg"
      },
      "source": [
        "### Q1 - 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnO2YvV0K4qQ"
      },
      "source": [
        "import graphviz \n",
        "from sklearn import tree\n",
        "\n",
        "my_data = tree.export_graphviz(clf, out_file=None, \n",
        "                      feature_names=X.columns,\n",
        "                      class_names = class_names,\n",
        "                      filled=True, rounded=True,\n",
        "                      special_characters=True)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X10bicLccx2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "01e8a28f-4a2e-4c93-9de1-2d9087986fbe"
      },
      "source": [
        "graph = graphviz.Source(my_data) \n",
        "graph"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f0808822cc0>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"582pt\" height=\"314pt\"\n viewBox=\"0.00 0.00 581.50 314.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 310)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-310 577.5,-310 577.5,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f4ccaf\" stroke=\"#000000\" d=\"M355,-306C355,-306 224,-306 224,-306 218,-306 212,-300 212,-294 212,-294 212,-235 212,-235 212,-229 218,-223 224,-223 224,-223 355,-223 355,-223 361,-223 367,-229 367,-235 367,-235 367,-294 367,-294 367,-300 361,-306 355,-306\"/>\n<text text-anchor=\"start\" x=\"220\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">worst radius ≤ 16.795</text>\n<text text-anchor=\"start\" x=\"251.5\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.468</text>\n<text text-anchor=\"start\" x=\"241.5\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 569</text>\n<text text-anchor=\"start\" x=\"231.5\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [357, 212]</text>\n<text text-anchor=\"start\" x=\"233\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = malignant</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#e78d4c\" stroke=\"#000000\" d=\"M282,-187C282,-187 101,-187 101,-187 95,-187 89,-181 89,-175 89,-175 89,-116 89,-116 89,-110 95,-104 101,-104 101,-104 282,-104 282,-104 288,-104 294,-110 294,-116 294,-116 294,-175 294,-175 294,-181 288,-187 282,-187\"/>\n<text text-anchor=\"start\" x=\"97\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">worst concave points ≤ 0.136</text>\n<text text-anchor=\"start\" x=\"153.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.159</text>\n<text text-anchor=\"start\" x=\"143.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 379</text>\n<text text-anchor=\"start\" x=\"137.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [346, 33]</text>\n<text text-anchor=\"start\" x=\"135\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = malignant</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M255.2244,-222.8796C247.8816,-213.9633 240.0524,-204.4565 232.4854,-195.268\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"234.9808,-192.7924 225.9219,-187.2981 229.5773,-197.2424 234.9808,-192.7924\"/>\n<text text-anchor=\"middle\" x=\"223.5138\" y=\"-208.4818\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#45a3e7\" stroke=\"#000000\" d=\"M453,-187C453,-187 324,-187 324,-187 318,-187 312,-181 312,-175 312,-175 312,-116 312,-116 312,-110 318,-104 324,-104 324,-104 453,-104 453,-104 459,-104 465,-110 465,-116 465,-116 465,-175 465,-175 465,-181 459,-187 453,-187\"/>\n<text text-anchor=\"start\" x=\"320\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">mean texture ≤ 16.11</text>\n<text text-anchor=\"start\" x=\"350.5\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.109</text>\n<text text-anchor=\"start\" x=\"340.5\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 190</text>\n<text text-anchor=\"start\" x=\"334.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [11, 179]</text>\n<text text-anchor=\"start\" x=\"341.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = benign</text>\n</g>\n<!-- 0&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>0&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M324.1254,-222.8796C331.618,-213.8733 339.6119,-204.2644 347.3279,-194.9897\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"350.0219,-197.224 353.7268,-187.2981 344.6407,-192.7472 350.0219,-197.224\"/>\n<text text-anchor=\"middle\" x=\"356.0108\" y=\"-208.4935\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#e5833c\" stroke=\"#000000\" d=\"M117,-68C117,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 117,0 117,0 123,0 129,-6 129,-12 129,-12 129,-56 129,-56 129,-62 123,-68 117,-68\"/>\n<text text-anchor=\"start\" x=\"31\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.03</text>\n<text text-anchor=\"start\" x=\"16.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 333</text>\n<text text-anchor=\"start\" x=\"14.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [328, 5]</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = malignant</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M144.2099,-103.9815C133.4275,-94.5151 121.977,-84.462 111.2187,-75.0168\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"113.3507,-72.2311 103.5268,-68.2637 108.7324,-77.4915 113.3507,-72.2311\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#b8dcf6\" stroke=\"#000000\" d=\"M251.5,-68C251.5,-68 159.5,-68 159.5,-68 153.5,-68 147.5,-62 147.5,-56 147.5,-56 147.5,-12 147.5,-12 147.5,-6 153.5,0 159.5,0 159.5,0 251.5,0 251.5,0 257.5,0 263.5,-6 263.5,-12 263.5,-12 263.5,-56 263.5,-56 263.5,-62 257.5,-68 251.5,-68\"/>\n<text text-anchor=\"start\" x=\"167.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.476</text>\n<text text-anchor=\"start\" x=\"161.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 46</text>\n<text text-anchor=\"start\" x=\"155.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [18, 28]</text>\n<text text-anchor=\"start\" x=\"158.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = benign</text>\n</g>\n<!-- 1&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>1&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M196.7131,-103.9815C197.7632,-95.618 198.8708,-86.7965 199.9325,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"203.4247,-78.6218 201.1978,-68.2637 196.4792,-77.7497 203.4247,-78.6218\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#fcf1e9\" stroke=\"#000000\" d=\"M427,-68C427,-68 322,-68 322,-68 316,-68 310,-62 310,-56 310,-56 310,-12 310,-12 310,-6 316,0 322,0 322,0 427,0 427,0 433,0 439,-6 439,-12 439,-12 439,-56 439,-56 439,-62 433,-68 427,-68\"/>\n<text text-anchor=\"start\" x=\"336.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.498</text>\n<text text-anchor=\"start\" x=\"330.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 17</text>\n<text text-anchor=\"start\" x=\"333\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [9, 8]</text>\n<text text-anchor=\"start\" x=\"318\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = malignant</text>\n</g>\n<!-- 4&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>4&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M383.2869,-103.9815C382.2368,-95.618 381.1292,-86.7965 380.0675,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"383.5208,-77.7497 378.8022,-68.2637 376.5753,-78.6218 383.5208,-77.7497\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#3b9ee5\" stroke=\"#000000\" d=\"M561.5,-68C561.5,-68 469.5,-68 469.5,-68 463.5,-68 457.5,-62 457.5,-56 457.5,-56 457.5,-12 457.5,-12 457.5,-6 463.5,0 469.5,0 469.5,0 561.5,0 561.5,0 567.5,0 573.5,-6 573.5,-12 573.5,-12 573.5,-56 573.5,-56 573.5,-62 567.5,-68 561.5,-68\"/>\n<text text-anchor=\"start\" x=\"477.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">gini = 0.023</text>\n<text text-anchor=\"start\" x=\"467.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 173</text>\n<text text-anchor=\"start\" x=\"465.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2, 171]</text>\n<text text-anchor=\"start\" x=\"468.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = benign</text>\n</g>\n<!-- 4&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>4&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M435.7901,-103.9815C446.5725,-94.5151 458.023,-84.462 468.7813,-75.0168\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"471.2676,-77.4915 476.4732,-68.2637 466.6493,-72.2311 471.2676,-77.4915\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zm9wpj-T5J64"
      },
      "source": [
        "### Q1 - 3\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHJhk_3xmHN4"
      },
      "source": [
        "#### a)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trQIkNO6mJfX"
      },
      "source": [
        "*   In case of sample i, worst radius = 10, which is less than that of the root value. So we traverse the left subtree of the root node. Then we check for the worst concave points which is 0.1 and compare it with 0.136. Since it is smaller, we again traverse the left subtree. So, checking the third condition is immaterial now and we choose the class as **malignant**.\n",
        "\n",
        "*   In case of sample ii, worst radius = 20. We compare it with the root node value which is 16.795. Since, it is greeater than the root node value, we traverse the right subtree of the root node. Then we check for the mean texture which is 35 and compare it with 16.11. Since, it is again greater, we traverse the right subtree again. So, now checking the third condition is immaterial now and we choose the class as **benign**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELk_ozwXoxYn"
      },
      "source": [
        "#### b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9XTKIJGo4es"
      },
      "source": [
        "*   In case of sample iii, worst radius = 12, so we traverse the left subtree of the root node. Then we check for the worst concave points which is 0.25 and hence we traverse the right subtree. So, now checking the third condition is immaterial now and we choose the class as **benign**.\n",
        "\n",
        "*   In case of sample iv, worst radius = 35, so we traverse the right subtree of the root node. Then we check for the mean texture which is 16 and hence we traverse the left subtree. So, now checking the third condition is immaterial now and we choose the class as **malignant**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTjMTS69jjWA"
      },
      "source": [
        "### Q1 - 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPWPmG8TjM0I"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Randomly splitting the data into training and testing with a ratio of 3:1\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state = 20)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lArLCkA45dP4"
      },
      "source": [
        "### Q1 - 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiGBR9x5pnFx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "b210e084-5eeb-4a8f-ad0a-37873a753949"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Hyperparameter list for optimization\n",
        "params = {'max_leaf_nodes': list(range(2, 100)), 'min_samples_split': [2, 3, 4]}\n",
        "\n",
        "# Creating the object for the decision tree classifier\n",
        "clf2 = DecisionTreeClassifier(random_state=20)\n",
        "\n",
        "# Instantiating the GridSearchCV object\n",
        "clf2_cv = GridSearchCV(clf2,params, cv=5)\n",
        "\n",
        "# Fitting it to data\n",
        "clf2_cv.fit(X_train,y_train)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=20,\n",
              "                                              splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_leaf_nodes': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12,\n",
              "                                            13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "                                            22, 23, 24, 25, 26, 27, 28, 29, 30,\n",
              "                                            31, ...],\n",
              "                         'min_samples_split': [2, 3, 4]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZAsqOGq5vla"
      },
      "source": [
        "### Q1 - 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyDBQ6cpp4Mn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "cbc6775d-e4f7-41a2-bbd8-d3e8b7551bfc"
      },
      "source": [
        "# Displaying the best parameters after the 5-fold cross validation\n",
        "print(\"The best parameters are as follows\")\n",
        "print(clf2_cv.best_params_)\n",
        "print(\"\\n\")\n",
        "print(\"The best score for the best parameters is \" + str(clf2_cv.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best parameters are as follows\n",
            "{'max_leaf_nodes': 7, 'min_samples_split': 2}\n",
            "\n",
            "\n",
            "The best score for the best parameters is 0.94593707250342\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIz3G2ntu7RY"
      },
      "source": [
        "*   Hence, the best hyperparameters are max_leaf_nodes = 7 and min_samples_split = 2. \n",
        "\n",
        "*   Also the best score for the best parameters  = 0.946\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5avr5R-m500L"
      },
      "source": [
        "### Q1 - 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbSJy-MHqXD_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "119722a2-71a4-4b52-eacd-bffd671ed3d6"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Training the model on the hyperparameters found\n",
        "clf3 = DecisionTreeClassifier(random_state=20, max_leaf_nodes=7, min_samples_split=2).fit(X_train,y_train)\n",
        "\n",
        "# Testing it on the test data\n",
        "y_pred = clf3.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "# Displaying the test accuracy\n",
        "print(\"The model's accuracy on the test set is \" + str(accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model's accuracy on the test set is 0.9020979020979021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TwwJokW6IpF"
      },
      "source": [
        "### Q1 - 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD3ELMbo75yl"
      },
      "source": [
        "The disadvantages of decision tree is as follows.\n",
        "\n",
        "*   **Lack of smoothness**.\n",
        "*   **Lack of stability, high variance** - A small change in the data can cause a large change in the structure of the decision tree causing instability. \n",
        "*   It prone to **overfitting**.\n",
        "*   **Affected by noise** - Little bit of noise can make it unstable which leads to wrong predictions.\n",
        "*   **Not suitable for large dataset**s - If data size is large, then one single tree may grow complex and lead to overfitting. So in this case, we should use Random Forest instead of a single Decision Tree.\n",
        "\n",
        "To overcome the disadvantages:\n",
        "\n",
        "\n",
        "*   **To overcome over fitting** (too many splits): If we can limit the node size and the depth of the tree by pruning using cost-complexity criterion which defines the trade-off between goodness of fit and model .\n",
        "\n",
        "*   We make the tree more robust by building an ensemble using the bootstarp aggregation where each tree is treated individually which lead to the decrease in variance  and also limit over-fitting without substantially increasing error due to bias; which is called the **random forest**. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRvzBO4j5IRn"
      },
      "source": [
        "# Question 2 - Random Forests"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVdV2rZC6NNF"
      },
      "source": [
        "### Q2 - 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1JBBsX798Cd"
      },
      "source": [
        "*   **Forest**  is a collection of many Decision trees rather averaging the prediction of trees.\n",
        "\n",
        "*   **Random** means that we take a random sample of our training data before building the tree and also take a subset of features when splitting .\n",
        "\n",
        "*   A **random forest** is simply a collection of decision trees whose results are aggregated into one final result. Their ability to limit over-fitting without substantially increasing error due to bias is why they are such powerful models. One way Random Forests reduce variance is by training on different samples of the data. It combines output class labels of the individual trees to a final consensus class label. \n",
        "\n",
        "*   Random forest uses **randomness** if there are many features and when we want to classify, random forest uses a subset of all the features for splitting each node in each decision tree. So it combines hundreds of decision trees and trains each one separately using the bootstrapping by taking a limited number of features, then making a final prediction by averaging the prediction of each individual tree. So, independent predictions from multiple decision trees are combined to produce a final classification.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc2LoKjT6Pdy"
      },
      "source": [
        "### Q2 - 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7VYlUm5_fNU"
      },
      "source": [
        "There are two popular arguments on why bagging works.\n",
        "\n",
        "*   A limitation of Decision Trees is that they suffer from high variance. Using the method of bagging, the variance is averaged from multiple trees on different variants of the training set thereby improving the overall variance. \n",
        "\n",
        "*   Bagging is capable of having an equalization(also known as secondary effect) on the potential influence on examples. This in turn reduces the variance.\n",
        "\n",
        "From a Bayesian point of view, Bagging works because:\n",
        "\n",
        "*   It is an approximation to the optimal procedure of Bayesian model averaging, with an appropriate implicit prior.\n",
        "\n",
        "*  Bagging effectively shifts the prior to a more appropriate region of model space. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q41tg__M6Q4L"
      },
      "source": [
        "### Q2 - 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwXd6xsJ5Gy0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "e39ca87f-7169-4c7b-9096-4025a5fa3a67"
      },
      "source": [
        "# Importing necessary packages\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from itertools import chain \n",
        "import numpy as np\n",
        "\n",
        "# Learning a classification of the breast cancer data with the RandomForestClassifier\n",
        "\n",
        "#Creating the classifier object wiht a max depth of 2\n",
        "clf4 = RandomForestClassifier(random_state=20)\n",
        "\n",
        "# Converting target dataframe to numpy array\n",
        "y = Y.values.tolist()\n",
        "y = list(chain.from_iterable(y))\n",
        "y = np.array(y)\n",
        "\n",
        "# Fitting the classifier to the data\n",
        "clf4.fit(X,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=20, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6r_IFXJq87VM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "outputId": "958f13f0-2c16-4ade-f865-a4792bf86554"
      },
      "source": [
        "# Hyperparameter list for optimization\n",
        "param_grid = { \n",
        "    'min_samples_split': [2, 3, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'max_leaf_nodes': list(range(10, 20)) #run before with wider range, but restricted to a subset for students to reduce run time\n",
        "}\n",
        "\n",
        "\n",
        "# Converting target dataframe of y_train to numpy array\n",
        "y2_train = y_train.values.tolist()\n",
        "y2_train = list(chain.from_iterable(y2_train))\n",
        "y2_train = np.array(y2_train)\n",
        "\n",
        "\n",
        "# Creating the object for the random forest classifier\n",
        "clf5 = RandomForestClassifier(random_state=20)\n",
        "\n",
        "# Instantiating the GridSearchCV object\n",
        "clf5_cv = GridSearchCV(clf5,param_grid, cv=5)\n",
        "\n",
        "# Fitting it to data\n",
        "clf5_cv.fit(X_train,y2_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=5, error_score=nan,\n",
              "             estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
              "                                              class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features='auto',\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              max_samples=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              n_estimators=100, n_jobs=None,\n",
              "                                              oob_score=False, random_state=20,\n",
              "                                              verbose=0, warm_start=False),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_features': ['auto', 'sqrt', 'log2'],\n",
              "                         'max_leaf_nodes': [10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
              "                                            19],\n",
              "                         'min_samples_split': [2, 3, 4]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 246
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MS2yduN6UZ_"
      },
      "source": [
        "### Q2 - 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66KfX4ktxHeQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "a82e6506-51aa-4e58-e267-5429aeaebf01"
      },
      "source": [
        "# Displaying the best parameters after the 5-fold cross validation\n",
        "print(\"The best parameters are as follows\")\n",
        "print(clf5_cv.best_params_)\n",
        "print(\"\\n\")\n",
        "print(\"The best score for the best parameters is \" + str(clf5_cv.best_score_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The best parameters are as follows\n",
            "{'max_features': 'auto', 'max_leaf_nodes': 15, 'min_samples_split': 2}\n",
            "\n",
            "\n",
            "The best score for the best parameters is 0.955403556771546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qu34Rw6DE4Fy"
      },
      "source": [
        "*   Hence, the best hyperparameters are max_features = auto, max_leaf_nodes = 15 and min_samples_split = 2. \n",
        "\n",
        "*   Also the best score for the best parameters  = 0.955\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5nqjFCS6WtX"
      },
      "source": [
        "### Q2 - 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi7kANc11RlQ"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Fitting the model on the best hyperparameters found\n",
        "clf6 = RandomForestClassifier(random_state=20, max_features='auto', max_leaf_nodes=15, min_samples_split=2).fit(X_train,y2_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5SgoHFq6aTp"
      },
      "source": [
        "### Q2 - 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaPlAJRg5jld",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0fcb65c-62f7-48c3-e792-6705b2bfcc09"
      },
      "source": [
        "# Predicting the classes of the test set\n",
        "y_pred =clf6.predict(X_test)\n",
        "y_pred2 = y_pred.tolist()\n",
        "\n",
        "# Storing the indices of the test dataset\n",
        "idx = X_test.index.to_list()\n",
        "\n",
        "for i in range(0,len(idx)):\n",
        "  print(\"For index = \" + str(idx[i]) + \", class = \"+ str(y_pred2[i]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For index = 269, class = benign\n",
            "For index = 263, class = malignant\n",
            "For index = 30, class = malignant\n",
            "For index = 452, class = benign\n",
            "For index = 214, class = malignant\n",
            "For index = 181, class = malignant\n",
            "For index = 32, class = malignant\n",
            "For index = 248, class = benign\n",
            "For index = 318, class = benign\n",
            "For index = 352, class = malignant\n",
            "For index = 317, class = malignant\n",
            "For index = 52, class = benign\n",
            "For index = 356, class = benign\n",
            "For index = 45, class = malignant\n",
            "For index = 496, class = benign\n",
            "For index = 440, class = benign\n",
            "For index = 467, class = benign\n",
            "For index = 261, class = malignant\n",
            "For index = 94, class = malignant\n",
            "For index = 505, class = benign\n",
            "For index = 427, class = benign\n",
            "For index = 166, class = benign\n",
            "For index = 29, class = malignant\n",
            "For index = 16, class = malignant\n",
            "For index = 129, class = malignant\n",
            "For index = 77, class = malignant\n",
            "For index = 3, class = malignant\n",
            "For index = 453, class = benign\n",
            "For index = 238, class = benign\n",
            "For index = 394, class = benign\n",
            "For index = 385, class = benign\n",
            "For index = 459, class = benign\n",
            "For index = 23, class = malignant\n",
            "For index = 308, class = benign\n",
            "For index = 119, class = malignant\n",
            "For index = 366, class = malignant\n",
            "For index = 156, class = malignant\n",
            "For index = 482, class = benign\n",
            "For index = 328, class = malignant\n",
            "For index = 187, class = benign\n",
            "For index = 56, class = malignant\n",
            "For index = 380, class = benign\n",
            "For index = 443, class = benign\n",
            "For index = 296, class = benign\n",
            "For index = 487, class = malignant\n",
            "For index = 92, class = benign\n",
            "For index = 90, class = benign\n",
            "For index = 221, class = benign\n",
            "For index = 136, class = benign\n",
            "For index = 351, class = malignant\n",
            "For index = 551, class = benign\n",
            "For index = 359, class = benign\n",
            "For index = 498, class = malignant\n",
            "For index = 217, class = benign\n",
            "For index = 191, class = benign\n",
            "For index = 145, class = benign\n",
            "For index = 454, class = benign\n",
            "For index = 204, class = benign\n",
            "For index = 447, class = benign\n",
            "For index = 80, class = benign\n",
            "For index = 46, class = benign\n",
            "For index = 165, class = benign\n",
            "For index = 348, class = benign\n",
            "For index = 497, class = benign\n",
            "For index = 105, class = malignant\n",
            "For index = 522, class = benign\n",
            "For index = 34, class = malignant\n",
            "For index = 268, class = benign\n",
            "For index = 319, class = benign\n",
            "For index = 31, class = malignant\n",
            "For index = 172, class = malignant\n",
            "For index = 141, class = malignant\n",
            "For index = 449, class = malignant\n",
            "For index = 150, class = benign\n",
            "For index = 20, class = benign\n",
            "For index = 18, class = malignant\n",
            "For index = 121, class = malignant\n",
            "For index = 182, class = malignant\n",
            "For index = 368, class = malignant\n",
            "For index = 290, class = malignant\n",
            "For index = 378, class = benign\n",
            "For index = 91, class = malignant\n",
            "For index = 63, class = benign\n",
            "For index = 115, class = benign\n",
            "For index = 333, class = benign\n",
            "For index = 127, class = malignant\n",
            "For index = 490, class = benign\n",
            "For index = 424, class = benign\n",
            "For index = 106, class = benign\n",
            "For index = 507, class = benign\n",
            "For index = 74, class = benign\n",
            "For index = 33, class = malignant\n",
            "For index = 59, class = benign\n",
            "For index = 354, class = benign\n",
            "For index = 564, class = malignant\n",
            "For index = 536, class = malignant\n",
            "For index = 10, class = malignant\n",
            "For index = 471, class = benign\n",
            "For index = 147, class = benign\n",
            "For index = 500, class = benign\n",
            "For index = 71, class = benign\n",
            "For index = 253, class = malignant\n",
            "For index = 53, class = malignant\n",
            "For index = 35, class = malignant\n",
            "For index = 93, class = benign\n",
            "For index = 411, class = benign\n",
            "For index = 353, class = malignant\n",
            "For index = 283, class = malignant\n",
            "For index = 557, class = benign\n",
            "For index = 17, class = malignant\n",
            "For index = 504, class = benign\n",
            "For index = 346, class = benign\n",
            "For index = 14, class = malignant\n",
            "For index = 110, class = benign\n",
            "For index = 412, class = benign\n",
            "For index = 461, class = malignant\n",
            "For index = 532, class = benign\n",
            "For index = 495, class = benign\n",
            "For index = 13, class = malignant\n",
            "For index = 24, class = malignant\n",
            "For index = 511, class = benign\n",
            "For index = 148, class = benign\n",
            "For index = 272, class = malignant\n",
            "For index = 320, class = benign\n",
            "For index = 323, class = malignant\n",
            "For index = 416, class = benign\n",
            "For index = 209, class = benign\n",
            "For index = 81, class = malignant\n",
            "For index = 520, class = benign\n",
            "For index = 544, class = benign\n",
            "For index = 128, class = malignant\n",
            "For index = 219, class = malignant\n",
            "For index = 406, class = benign\n",
            "For index = 390, class = benign\n",
            "For index = 350, class = benign\n",
            "For index = 446, class = malignant\n",
            "For index = 175, class = benign\n",
            "For index = 257, class = malignant\n",
            "For index = 477, class = benign\n",
            "For index = 140, class = benign\n",
            "For index = 7, class = malignant\n",
            "For index = 281, class = benign\n",
            "For index = 84, class = benign\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf9qyYJGUWGJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ef27469a-f4f5-405b-8754-dbabddd4a745"
      },
      "source": [
        "# Printing the number of samples in test data assigned to each class\n",
        "d = {x:y_pred2.count(x) for x in y_pred2}\n",
        "print(d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'benign': 84, 'malignant': 59}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNmEDefp6jiP"
      },
      "source": [
        "### Q2 - 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAI_UGQs6VHl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "outputId": "1d6f2d86-5ef7-49a3-df98-97f609223380"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "cm = confusion_matrix(y_test,y_pred)\n",
        "\n",
        "# Displaying the test accuracy\n",
        "print(\"The model's accuracy on the test set is \" + str(accuracy))\n",
        "print()\n",
        "# Displaying the confusion matrix\n",
        "print(\"The confusion matrix is as follows:\")\n",
        "print(cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model's accuracy on the test set is 0.972027972027972\n",
            "\n",
            "The confusion matrix is as follows:\n",
            "[[83  3]\n",
            " [ 1 56]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTrs5wWg6nb0"
      },
      "source": [
        "### Q2 - 8"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P2Ap6eTcAW3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "bc6b739f-8bc2-42cb-86b8-499dc5262cea"
      },
      "source": [
        "# Storing all the feature names in a list\n",
        "feature_names = X.columns.to_list()\n",
        "\n",
        "# Extract feature importances\n",
        "f = pd.DataFrame({'features': feature_names, 'importance': clf6.feature_importances_}).sort_values('importance', ascending = False)\n",
        "\n",
        "print(f)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                   features  importance\n",
            "7       mean concave points    0.155255\n",
            "22          worst perimeter    0.121300\n",
            "23               worst area    0.115884\n",
            "27     worst concave points    0.109546\n",
            "6            mean concavity    0.075353\n",
            "20             worst radius    0.066466\n",
            "26          worst concavity    0.044549\n",
            "0               mean radius    0.039732\n",
            "13               area error    0.038943\n",
            "3                 mean area    0.034723\n",
            "2            mean perimeter    0.027355\n",
            "12          perimeter error    0.025323\n",
            "10             radius error    0.019157\n",
            "24         worst smoothness    0.015974\n",
            "28           worst symmetry    0.015184\n",
            "1              mean texture    0.014486\n",
            "21            worst texture    0.014091\n",
            "5          mean compactness    0.013392\n",
            "25        worst compactness    0.008686\n",
            "29  worst fractal dimension    0.005334\n",
            "4           mean smoothness    0.004986\n",
            "11            texture error    0.004959\n",
            "15        compactness error    0.004729\n",
            "16          concavity error    0.004558\n",
            "19  fractal dimension error    0.004333\n",
            "18           symmetry error    0.004040\n",
            "14         smoothness error    0.003458\n",
            "8             mean symmetry    0.003447\n",
            "17     concave points error    0.002405\n",
            "9    mean fractal dimension    0.002353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlBAW4RO6zuS"
      },
      "source": [
        "### Q2 - 9\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8YK3J9hDR8M"
      },
      "source": [
        "# The most four most important features of the random forest classifier are as follows:\n",
        "\n",
        "*   It estimates which variables are important in classification and does an unbiased estimate of error during the building process.\n",
        "\n",
        "*   It works pretty well on large datasets, hence can be used in real-life scenario that uses huge amount of data for training and testing. \n",
        "\n",
        "*   It makes the decision trees more robust by building an ensemble and can also handle thousands of input variables without variable deletion. Also, it does not suffer from over-fitting.\n",
        "\n",
        "*   It has an effective method for estimating missing data and maintains accuracy when a large proportion of the data are missing.\n",
        "\n",
        "For the **RandomForestClassifier** module of sklearn the important features are:\n",
        "\n",
        "*   It is resposible for fitting a number of decision tree classifiers on various sub-samples of the dataset and improves the accuracy by averaging the scores of the decision trees. \n",
        "\n",
        "*   max_samples parameter is a very essential parameter which is used to control the sub-sample size.\n",
        "\n",
        "*   If the default values of the classifier is kept, then it will lead to a fully grown tree which may be very large if the dataset is large. Hence, the parameters  max_depth, min_samples_leaf should be chosen so that a reasonable tree is obtained.\n",
        "\n",
        "*   There is always a random permutation of the features at each split. Hence, finding the best split may be a challege. However, for a fixed fitting behaviour, random state must be fixed each time. "
      ]
    }
  ]
}